{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "!pip install -q kaggle\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../root/\n",
    "!mkdir .kaggle\n",
    "%cd .kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d grassknoted/asl-alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization, Add, Input, ZeroPadding2D, AveragePooling2D\n",
    "from keras.initializers import glorot_uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "from numpy import floor\n",
    "import random\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip asl-alphabet.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './asl_alphabet_train/asl_alphabet_train'\n",
    "path_test = './asl_alphabet_test/asl_alphabet_test'\n",
    "target_size = (64,64)\n",
    "target_dims = (64,64,3)\n",
    "val_frac = 0.1\n",
    "n_classes = 29\n",
    "batch_size = 64\n",
    "\n",
    "image_generator = ImageDataGenerator(samplewise_center = True, samplewise_std_normalization = True, validation_split=val_frac)\n",
    "\n",
    "train_gen = image_generator.flow_from_directory(path, target_size=target_size, batch_size=batch_size, shuffle=True, subset='training')\n",
    "val_gen = image_generator.flow_from_directory(path, target_size=target_size, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X,f,filters, stage, block):\n",
    "  #defining name basis\n",
    "  conv_name_base = 'res' +str(stage)+block+'_branch'\n",
    "  bn_name_base = 'bn' +str(stage)+block+'_branch'\n",
    "\n",
    "  #Retrive Filters\n",
    "  F1,F2,F3 = filters\n",
    "\n",
    "  X_shortcut = X\n",
    "\n",
    "  X = Conv2D(filters=F1, kernel_size=(1,1), strides = (1,1), padding='valid', name = conv_name_base+'2a',kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "  X = BatchNormalization(axis = 3, name = bn_name_base+'2a')(X)\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  X = Conv2D(filters=F2, kernel_size=(f,f), strides = (1,1), padding='same', name = conv_name_base+'2b',kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "  X = BatchNormalization(axis = 3, name = bn_name_base+'2b')(X)\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  X = Conv2D(filters=F3, kernel_size=(1,1), strides = (1,1), padding='valid', name = conv_name_base+'2c',kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "  X = BatchNormalization(axis = 3, name = bn_name_base+'2c')(X)\n",
    "  X = Add()([X, X_shortcut])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "  conv_name_base = 'res' +str(stage)+block+'_branch'\n",
    "  bn_name_base = 'bn' +str(stage)+block+'_branch'\n",
    "\n",
    "  F1,F2,F3 = filters\n",
    "\n",
    "  X_shortcut = X\n",
    "\n",
    "  X = Conv2D(filters=F1, kernel_size=(1,1), strides = (s,s), name = conv_name_base+'2a',kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "  X = BatchNormalization(axis = 3, name = bn_name_base+'2a')(X)\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  X = Conv2D(filters=F2, kernel_size=(f,f), strides = (1,1),padding='same', name = conv_name_base+'2b',kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "  X = BatchNormalization(axis = 3, name = bn_name_base+'2b')(X)\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  X = Conv2D(filters=F3, kernel_size=(1,1), strides = (1,1),padding='valid', name = conv_name_base+'2c',kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "  X = BatchNormalization(axis = 3, name = bn_name_base+'2c')(X)\n",
    "\n",
    "  X_shortcut = Conv2D(filters=F3, kernel_size=(1,1), strides = (s,s), name = conv_name_base+'1',kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "  X_shortcut = BatchNormalization(axis = 3, name = bn_name_base+'1')(X_shortcut)\n",
    "  X = Add() ([X, X_shortcut])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64,64,3), classes = 29):\n",
    "  X_input = Input(input_shape)\n",
    "\n",
    "  #Zero padding\n",
    "  X = ZeroPadding2D((3,3))(X_input)\n",
    "\n",
    "  #stage 1\n",
    "  X = Conv2D(64,(7,7),strides=(2,2), name = 'conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "  X = BatchNormalization(axis=3, name = 'bn_conv1')(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((3,3), strides=(2,2))(X)\n",
    "\n",
    "  #stage 2\n",
    "  X = convolutional_block(X, f=3, filters=[64, 64, 256], stage = 2, block='a', s=1)\n",
    "  X = identity_block(X, 3, [64,64,256], stage=2, block='b')\n",
    "  X = identity_block(X,3,[64,64,256], stage = 2, block = 'c')\n",
    "\n",
    "  #stage 3\n",
    "  X = convolutional_block(X, f=3, filters=[128, 128, 512], stage = 3, block='a', s=2)\n",
    "  X = identity_block(X, 3, filters=[128, 128, 512], stage=3, block='b')\n",
    "  X = identity_block(X,3,filters=[128, 128, 512], stage = 3, block = 'c')\n",
    "  X = identity_block(X,3,filters=[128, 128, 512], stage = 3, block = 'd')\n",
    "\n",
    "  #stage 4\n",
    "  X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage = 4, block='a', s=2)\n",
    "  X = identity_block(X, 3, filters=[256, 256, 1024], stage=4, block='b')\n",
    "  X = identity_block(X,3,filters=[256, 256, 1024], stage = 4, block = 'c')\n",
    "  X = identity_block(X,3,filters=[256, 256, 1024], stage = 4, block = 'd')\n",
    "  X = identity_block(X,3,filters=[256, 256, 1024], stage = 4, block = 'f')\n",
    "\n",
    "  #stage 5\n",
    "  X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage = 5, block='a', s=2)\n",
    "  X = identity_block(X, 3, filters=[512, 512, 2048], stage=5, block='b')\n",
    "  X = identity_block(X,3,filters=[512, 512, 2048], stage = 5, block = 'c')\n",
    "\n",
    "  X = AveragePooling2D((2,2), name = 'avg_pool')(X)\n",
    "\n",
    "  X = Flatten()(X)\n",
    "  X = Dense(classes, activation='softmax', name='fc'+str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "  model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "history = model.fit_generator(train_gen,epochs=10, validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../../content/Resnet50v2.h5')\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "np.argmax(predictions[0]), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_image(pridiction_arr, true_labels_arr, images_arr):\n",
    "  class_names = ['a', 'b','c','d','e', 'f','g','h','i','j','k']\n",
    "  plt.figure(figsize(15,5))\n",
    "  for i in range(1,11):\n",
    "    prediction = pridiction_arr[i]\n",
    "    true_label = true_labels_arr[i]\n",
    "    img = images_arr[i]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap= plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(prediction)\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "      color = 'blue'\n",
    "    else:\n",
    "      color = 'red'\n",
    "    plt.xlabel(\"Predicted: {} {:2.0f}% (True: {})\".format(class_names[predicted_label],\n",
    "                                  100*np.max(prediction),\n",
    "                                  class_names[true_label]),\n",
    "                                  color=color)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
